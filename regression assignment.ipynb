{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28309b5d",
   "metadata": {},
   "source": [
    "# Regression\n",
    "### Assignment Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f33ec3",
   "metadata": {},
   "source": [
    "**Q1. What is Simple Linear Regression?**\n",
    " - Simple Linear Regression is a statistical method used to model the relationship between two variables. It helps in predicting the value of one variable based on the value of another. This technique assumes a linear relationship between the dependent variable (Y) and the independent variable (X).\n",
    "\n",
    "Mathematically, it is represented by the equation:\n",
    "\n",
    "\\[\n",
    "Y = mX + c\n",
    "\\]\n",
    "\n",
    "where:\n",
    "- \\( Y \\) is the dependent variable,\n",
    "- \\( X \\) is the independent variable,\n",
    "- \\( m \\) is the slope (indicating the rate of change in \\( Y \\) per unit change in \\( X \\)),\n",
    "- \\( c \\) is the intercept (the value of \\( Y \\) when \\( X \\) is zero).\n",
    "\n",
    "Simple Linear Regression is widely used in various fields, such as finance, economics, and machine learning, for forecasting and data analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeebddd",
   "metadata": {},
   "source": [
    "**Q2.What are the key assumptions of Simple Linear Regression?**\n",
    " - Simple Linear Regression relies on several key assumptions to ensure accurate predictions and meaningful relationships between variables. Here are the most important ones:\n",
    "\n",
    "1. **Linearity** – The relationship between the independent variable \\( X \\) and the dependent variable \\( Y \\) must be linear. That is, a straight line should best represent the data.\n",
    "\n",
    "2. **Independence** – Observations in the dataset should be independent of each other. There should be no correlation between residuals (differences between actual and predicted values).\n",
    "\n",
    "3. **Homoscedasticity** – The variance of residuals should remain constant across all values of \\( X \\). This means the spread of errors should not change as \\( X \\) increases or decreases.\n",
    "\n",
    "4. **Normality of Residuals** – The errors or residuals should be normally distributed, particularly for small sample sizes. This ensures valid statistical inference.\n",
    "\n",
    "5. **No Multicollinearity** – Since Simple Linear Regression involves only one independent variable, multicollinearity (high correlation between multiple independent variables) does not apply. However, in multiple regression, this assumption is crucial.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36db99b",
   "metadata": {},
   "source": [
    "**Q3. What does the coefficient m represent in the equation Y=mX+c?**\n",
    "  - The coefficient \\( m \\) in the equation \\( Y = mX + c \\) represents the **slope** of the linear relationship between \\( X \\) (independent variable) and \\( Y \\) (dependent variable). It indicates how much \\( Y \\) changes for every **one-unit increase** in \\( X \\).\n",
    "\n",
    "### Interpretation:\n",
    "- If \\( m \\) is **positive**, \\( Y \\) increases as \\( X \\) increases (direct relationship).\n",
    "- If \\( m \\) is **negative**, \\( Y \\) decreases as \\( X \\) increases (inverse relationship).\n",
    "- If \\( m = 0 \\), there is **no relationship** between \\( X \\) and \\( Y \\), meaning \\( Y \\) remains constant regardless of changes in \\( X \\).\n",
    "\n",
    "In practical terms, this coefficient helps quantify the strength and direction of the relationship between variables. \n",
    "For example:-\n",
    "if you're analyzing how temperature affects ice cream sales, a **larger \\( m \\)** means a stronger correlation—higher temperatures lead to more sales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa763cad",
   "metadata": {},
   "source": [
    "**Q4.What does the intercept c represent in the equation Y=mX+c?**\n",
    " - In the equation Y=mX+c, which is a common form for a linear equation, the intercept c represents the value of Y when X is equal to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02e3c35",
   "metadata": {},
   "source": [
    "**Q5. How do we calculate the slope m in Simple Linear Regression?**\n",
    " - Great question! In Simple Linear Regression, the slope \\(m\\) represents the rate at which the dependent variable (\\(y\\)) changes with respect to the independent variable (\\(x\\)). It's calculated using the following formula:\n",
    "\n",
    "\\[\n",
    "m = \\frac{\\sum (x_i - \\bar{x}) (y_i - \\bar{y})}{\\sum (x_i - \\bar{x})^2}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( x_i \\) and \\( y_i \\) are individual data points.\n",
    "- \\( \\bar{x} \\) and \\( \\bar{y} \\) are the mean values of \\(x\\) and \\(y\\).\n",
    "- The numerator is the covariance between \\(x\\) and \\(y\\), showing how they vary together.\n",
    "- The denominator is the variance of \\(x\\), indicating how much \\(x\\) spreads from its mean.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50438655",
   "metadata": {},
   "source": [
    "**Q6.What is the purpose of the least squares method in Simple Linear Regression?**\n",
    "  - The least squares method in Simple Linear Regression serves to find the best-fitting line by minimizing the sum of squared residuals (errors). It ensures that the predicted values are as close as possible to the actual data points.\n",
    "  \n",
    "  # Here's why it's crucial:-\n",
    "- **Minimizing Error:** It calculates the difference between observed and predicted values, squares those differences, and sums them up. The goal is to make this sum as small as possible.\n",
    "- **Optimal Fit:** By adjusting the slope (\\(m\\)) and intercept (\\(b\\)), the method finds the line that best represents the trend in the data.\n",
    "- **Predictability:** A well-fitted regression line improves accuracy in predicting future values based on the independent variable.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ca2828",
   "metadata": {},
   "source": [
    "**Q7.How is the coefficient of determination (R²) interpreted in Simple Linear Regression?**\n",
    "  - The coefficient of determination, **(R²)**, is a key metric in Simple Linear Regression that indicates how well the model explains the variability of the dependent variable (\\( y \\)) based on the independent variable (\\( x \\)). Here's how to interpret it:\n",
    "\n",
    "- **Value Range:** (R²) ranges from 0 to 1.\n",
    "  - If \\( R² = 1 \\), it means the model perfectly explains all the variation in \\( y \\) using \\( x \\).\n",
    "  - If \\( R²= 0 \\), it suggests that \\( x \\) does not explain any variation in \\( y \\).\n",
    "  - Higher values (closer to 1) indicate a stronger relationship, while lower values show a weaker correlation.\n",
    "\n",
    "- **Explained Variance:** It tells us the proportion of total variation in \\( y \\) that is explained by the regression model.\n",
    "  \\[\n",
    "  R² = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\n",
    "  \\]\n",
    "  where:\n",
    "  - \\( y_i \\) = actual values,\n",
    "  - \\( \\hat{y}_i \\) = predicted values,\n",
    "  - \\( \\bar{y} \\) = mean of \\( y \\).\n",
    "\n",
    "- **Limitations:** A high \\( R² \\) does not always mean the model is good—it could be misleading if the relationship is non-linear or influenced by outliers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d2ef17",
   "metadata": {},
   "source": [
    "**Q8.What is Multiple Linear Regression?**\n",
    "  - Multiple Linear Regression (MLR) is a statistical technique used to model the linear relationship between a dependent variable and two or more independent variables. It's an extension of simple linear regression, which only considers one independent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd02c80",
   "metadata": {},
   "source": [
    "**Q9. What is the main difference between Simple and Multiple Linear Regression?**\n",
    "  - The key difference between **Simple Linear Regression** and **Multiple Linear Regression** lies in the number of independent variables:\n",
    "\n",
    "- **Simple Linear Regression (SLR)**:  \n",
    "  - Involves **one** independent variable (\\( x \\)).\n",
    "  - Models the relationship between \\( x \\) and \\( y \\) with a straight line.  \n",
    "  - Formula:  \n",
    "    \\[\n",
    "    y = b_0 + b_1x + \\varepsilon\n",
    "    \\]\n",
    "  - Example: Predicting house price based on **only** square footage.\n",
    "\n",
    "- **Multiple Linear Regression (MLR)**:  \n",
    "  - Involves **two or more** independent variables (\\( x_1, x_2, x_3, \\dots \\)).\n",
    "  - Models the impact of multiple factors on \\( y \\).  \n",
    "  - Formula:  \n",
    "    \\[\n",
    "    y = b_0 + b_1x_1 + b_2x_2 + \\dots + b_nx_n + \\varepsilon\n",
    "    \\]\n",
    "  - **Example:-** Predicting house price using **square footage, number of rooms, and location**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be9ebd1",
   "metadata": {},
   "source": [
    "**Q10. What are the key assumptions of Multiple Linear Regression?**\n",
    "   - Multiple Linear Regression (MLR) relies on several key assumptions to ensure accurate and meaningful results.\n",
    "    \n",
    "   - **Important main assumptions:-**\n",
    "\n",
    "   1. **Linearity** – The relationship between the dependent variable (\\( y \\)) and independent variables (\\( x_1, x_2, \\dots \\)) should be linear. If the relationship is non-linear, transformations or other models may be needed.\n",
    "\n",
    "   2. **Independence** – Observations should be independent of each other. If there's dependence (like time-series data), adjustments such as autocorrelation tests should be performed.\n",
    "\n",
    "   3. **Homoscedasticity** – The variance of residuals (errors) should remain constant across all levels of the independent variables. If residuals spread unevenly, heteroscedasticity might be present, which can impact model reliability.\n",
    "\n",
    "   4. **No Multicollinearity** – Independent variables should not be highly correlated with each other. Strong correlations can distort coefficient estimates, making the model unstable. Checking the **Variance Inflation Factor (VIF)** can help detect this issue.\n",
    "\n",
    "   5. **Normality of Residuals** – The residuals (errors) should follow a normal distribution. This ensures valid statistical inferences. Normality can be assessed using visualizations like histograms or formal tests like the **Shapiro-Wilk test**.\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24e5057",
   "metadata": {},
   "source": [
    "**Q11.What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?**\n",
    "   - Heteroscedasticity refers to a situation in Multiple Linear Regression where the **variance of residuals (errors) is not constant across all levels of the independent variables**. In other words, some data points have greater variability than others, leading to unequal spread in the residuals.\n",
    "\n",
    "### **Effects of Heteroscedasticity on Regression Results:**\n",
    "1. **Unreliable Coefficients** – The estimated regression coefficients (\\( b_1, b_2, \\dots \\)) remain **unbiased**, but their standard errors become **incorrect**, making hypothesis tests unreliable.\n",
    "2. **Inefficient Predictions** – Confidence intervals and p-values become **misleading**, leading to potential misinterpretations of statistical significance.\n",
    "3. **Over or Underestimated Errors** – It can affect **inferential statistics**, causing overconfidence in results or underestimating actual variability.\n",
    "4. **Violation of Assumptions** – The least squares method assumes **homoscedasticity** (constant variance). Violating this can lead to inefficient estimators.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368de581",
   "metadata": {},
   "source": [
    "**Q12. How can you improve a Multiple Linear Regression model with high multicollinearity?**\n",
    "   - When a Multiple Linear Regression model suffers from **high multicollinearity**, it means that independent variables are too closely correlated, making it difficult to determine their individual impact on the dependent variable.\n",
    "   \n",
    "   # Here’s how we can improve the model:-\n",
    "\n",
    "### **1. Check for Multicollinearity**  \n",
    "- Use the **Variance Inflation Factor (VIF)** to detect it.  \n",
    "  - If **VIF > 5 or 10**, it indicates strong multicollinearity.  \n",
    "- Look at **correlation matrices** to identify highly correlated predictors.\n",
    "\n",
    "### **2. Remove Highly Correlated Variables**  \n",
    "- If two variables provide nearly identical information, consider **dropping one** to reduce redundancy.\n",
    "\n",
    "### **3. Feature Selection Techniques**  \n",
    "- Use methods like **LASSO Regression** or **Principal Component Analysis (PCA)** to select the most important predictors.\n",
    "\n",
    "### **4. Standardize or Normalize Data**  \n",
    "- If variables have vastly different scales, applying **standardization (z-score)** or **normalization (min-max scaling)** can stabilize their influence.\n",
    "\n",
    "### **5. Use Ridge or LASSO Regression**  \n",
    "- **Ridge Regression** introduces a penalty term that **shrinks coefficients**, reducing multicollinearity's impact.  \n",
    "- **LASSO Regression** goes a step further by setting some coefficients to **zero**, effectively performing variable selection.\n",
    "\n",
    "### **6. Use Domain Knowledge**  \n",
    "- Instead of purely relying on statistical methods, evaluate variables based on **practical significance** rather than statistical correlation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b39c872",
   "metadata": {},
   "source": [
    "**Q13. What are some common techniques for transforming categorical variables for use in regression models?**\n",
    "  - Transforming categorical variables is an essential step in preparing data for regression models.\n",
    "  \n",
    "  # Here are some common techniques:-\n",
    "\n",
    "1. **One-Hot Encoding** – Converts categorical variables into multiple binary columns, where each category gets its own column with values of 0 or 1. This is useful when the categorical variable has no inherent order.\n",
    "\n",
    "2. **Label Encoding** – Assigns a unique numerical value to each category. This is commonly used for ordinal data, where categories have a meaningful order.\n",
    "\n",
    "3. **Binary Encoding** – A combination of label encoding and one-hot encoding, where categories are first assigned numerical values and then converted into binary representations spread across multiple columns. This helps reduce dimensionality compared to one-hot encoding.\n",
    "\n",
    "4. **Frequency Encoding** – Maps each category to the frequency of its occurrence in the dataset. This can be useful when the frequency of a category holds predictive power.\n",
    "\n",
    "5. **Target Encoding** – Replaces each category with the mean of the target variable for that category, making it useful for predictive modeling. However, it requires caution to avoid data leakage.\n",
    "\n",
    "6. **Embedding Representations** – Utilizes deep learning techniques to create dense numerical representations of categorical variables, often useful for large datasets with high-cardinality categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aaf893",
   "metadata": {},
   "source": [
    "**Q14. What is the role of interaction terms in Multiple Linear Regression?**\n",
    "   - Interaction terms in Multiple Linear Regression help capture relationships between variables that are not purely additive.\n",
    "    They allow the model to account for cases where the effect of one predictor on the dependent variable depends on the value of another predictor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bc6db3",
   "metadata": {},
   "source": [
    "**Q15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?**\n",
    "  - The interpretation of the intercept differs between Simple and Multiple Linear Regression due to the presence of additional predictors:-\n",
    "\n",
    "1. **Simple Linear Regression (\\( Y = \\beta_0 + \\beta_1X + \\epsilon \\))**  \n",
    "   - The intercept (\\( \\beta_0 \\)) represents the predicted value of \\( Y \\) when \\( X = 0 \\).\n",
    "   - If \\( X = 0 \\) is meaningful within the data range, \\( \\beta_0 \\) can be interpreted directly as the expected outcome in that scenario.\n",
    "   - If \\( X = 0 \\) is outside the observed range, the intercept becomes more theoretical and may not have a practical interpretation.\n",
    "\n",
    "2. **Multiple Linear Regression (\\( Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\dots + \\epsilon \\))**  \n",
    "   - The intercept (\\( \\beta_0 \\)) represents the predicted value of \\( Y \\) when **all predictor variables** (\\( X_1, X_2, \\dots \\)) are equal to zero.\n",
    "   - Similar to simple regression, its interpretability depends on whether the zero values of all predictors have a realistic meaning.\n",
    "   - Often, the intercept is not of primary interest in multiple regression, as it is mainly a baseline reference.\n",
    "\n",
    "   - In practice, if the zero values of the predictors are not meaningful, centering the variables (subtracting the mean from each value) can make the intercept more interpretable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cdd89d",
   "metadata": {},
   "source": [
    "**Q16.What is the significance of the slope in regression analysis, and how does it affect predictions?**\n",
    "   - The slope in regression analysis is crucial because it represents the **rate of change** of the dependent variable (\\( Y \\)) for every one-unit increase in the independent variable (\\( X \\)).\n",
    "   ### Importance of the slope in regression analysis:-\n",
    "\n",
    "1. **Interpreting Relationships** – The sign and magnitude of the slope tell us how \\( X \\) influences \\( Y \\):\n",
    "   - A **positive slope** means that as \\( X \\) increases, \\( Y \\) increases.\n",
    "   - A **negative slope** indicates that as \\( X \\) increases, \\( Y \\) decreases.\n",
    "   - A **zero slope** suggests no relationship between \\( X \\) and \\( Y \\).\n",
    "\n",
    "2. **Making Predictions** – The slope enables us to estimate future values. Given a linear equation (\\( Y = \\beta_0 + \\beta_1 X \\)), the slope (\\( \\beta_1 \\)) determines how much \\( Y \\) changes for each increase in \\( X \\).\n",
    "\n",
    "3. **Assessing Strength of Effect** – A larger absolute value of the slope indicates a stronger impact of \\( X \\) on \\( Y \\). A smaller absolute value suggests a weaker association.\n",
    "\n",
    "4. **Comparing Variables** – In multiple regression, different slopes show the relative importance of predictors. Standardizing variables can help compare their effects.\n",
    "\n",
    "5. **Understanding Causality** – While a slope shows correlation, it doesn’t always imply causation. Additional statistical tests and domain knowledge are needed to infer causality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c186f47",
   "metadata": {},
   "source": [
    "**Q17. How does the intercept in a regression model provide context for the relationship between variables?**\n",
    "  - The intercept in a regression model acts as the baseline reference point for the relationship between variables. It represents the predicted value of the dependent variable (( Y )) when all independent variables (( X )) are equal to zero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da6021d",
   "metadata": {},
   "source": [
    "**Q18.What are the limitations of using R² as a sole measure of model performance?**\n",
    "  - R² (the coefficient of determination) is a useful metric for assessing model fit, but relying on it alone has several limitations:\n",
    "\n",
    "1. **Does Not Indicate Predictive Accuracy** – A high R² doesn’t guarantee strong predictive performance on new data. Overfitting can lead to an artificially high R² while failing on unseen data.\n",
    "\n",
    "2. **Insensitive to Model Complexity** – R² can increase with more predictors, even if they don’t contribute meaningfully. Adjusted R² partially corrects this by penalizing unnecessary variables.\n",
    "\n",
    "3. **Ignores Model Assumptions** – It doesn’t check whether assumptions like linearity, normality, or homoscedasticity are met, which can lead to misleading interpretations.\n",
    "\n",
    "4. **Cannot Detect Collinearity** – High correlation among independent variables (multicollinearity) can distort interpretations of variable importance, yet R² alone doesn’t account for it.\n",
    "\n",
    "5. **Misleading in Certain Data Distributions** – In datasets with high variability, a low R² might still indicate a useful model. Conversely, a high R² doesn’t guarantee practical significance.\n",
    "\n",
    "6. **Does Not Address Bias or Errors** – Other metrics like RMSE, MAE, or residual analysis provide deeper insights into prediction errors and bias.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb41890e",
   "metadata": {},
   "source": [
    "**Q19. How would you interpret a large standard error for a regression coefficient?**\n",
    "   - A large standard error for a regression coefficient suggests **greater uncertainty** in estimating that coefficient.\n",
    "   \n",
    "   ## Here’s how to interpret it:-\n",
    "\n",
    "   - 1. **High Variability in Estimates** – A large standard error means that repeated sampling could yield widely varying coefficient estimates, reducing reliability.\n",
    "\n",
    "   - 2. **Weak Relationship with the Dependent Variable** – It may indicate that the predictor doesn’t have a strong or consistent effect on the response variable.\n",
    "\n",
    "   - 3. **Potential Multicollinearity Issues** – If predictors are highly correlated, standard errors inflate, making it difficult to distinguish individual variable contributions.\n",
    "\n",
    "   - 4. **Insufficient Sample Size** – A small dataset may not provide enough information to estimate coefficients precisely, leading to higher standard errors.\n",
    "\n",
    "   - 5. **Presence of Outliers or Noise** – Extreme values or high variance in the data can contribute to instability in coefficient estimation.\n",
    "\n",
    "   - 6. **Impact on Hypothesis Testing** – A large standard error increases the probability that the confidence interval for the coefficient includes zero, potentially making it statistically insignificant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c5c9d6",
   "metadata": {},
   "source": [
    "**Q20.How can heteroscedasticity be identified in residual plots, and why is it important to address it?**\n",
    "   - Heteroscedasticity refers to a situation where the variance of residuals (errors) changes across levels of an independent variable. Identifying and addressing it is essential to ensure valid regression analysis.\n",
    "\n",
    "   ## **How to Identify Heteroscedasticity in Residual Plots**\n",
    "   - 1. **Scatter Plot of Residuals vs. Fitted Values** – Look for a pattern where residuals spread out unevenly as predicted values increase, often forming a cone shape.\n",
    "   - 2. **Residual vs. Predictor Variable Plots** – If plotting residuals against individual predictors shows non-constant spread, it’s a sign of heteroscedasticity.\n",
    "   - 3. **Breusch-Pagan or White Test** – These statistical tests formally detect heteroscedasticity by examining the relationship between residual variance and predictors.\n",
    "   - 4. **Boxplots or Variance Comparisons Across Groups** – If categorical predictors exhibit different variances in residuals across levels, heteroscedasticity might be present.\n",
    "\n",
    "   ## **Importance:-**\n",
    "   - 1. **Biased Standard Errors** – Unequal residual variance can lead to incorrect estimation of standard errors, affecting hypothesis testing.\n",
    "   - 2. **Inefficient Estimates** – Ordinary Least Squares (OLS) assumes constant variance; when violated, parameter estimates may lose efficiency.\n",
    "   - 3. **Invalid Confidence Intervals and p-Values** – Inflated or deflated standard errors can make coefficients appear statistically significant or insignificant incorrectly.\n",
    "   - 4. **Misleading Predictions** – Model reliability suffers, potentially leading to erroneous forecasting and decision-making.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defc42f3",
   "metadata": {},
   "source": [
    "**Q21. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?**\n",
    "   - If a Multiple Linear Regression model has a high R-squared (R2) but a low adjusted R-squared (Adjusted R2), it means the model is likely overfitting the training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c68ea08",
   "metadata": {},
   "source": [
    "**Q22.Why is it important to scale variables in Multiple Linear Regression?**\n",
    "   - Scaling variables in Multiple Linear Regression is important because it helps improve model performance and interpretability.\n",
    "   \n",
    "   -  **Here’s why:-**\n",
    "\n",
    "### **1. Preventing Bias from Magnitude Differences**\n",
    "   - Variables with large numerical ranges can dominate those with smaller ranges, making coefficient estimates misleading.\n",
    "   - Scaling ensures all predictors contribute proportionally to the regression model.\n",
    "\n",
    "### **2. Enhancing Stability in Optimization**\n",
    "   - Regression algorithms use numerical optimization techniques, and unscaled variables can cause instability or slow convergence.\n",
    "   - Scaling helps gradient-based optimization methods find solutions more efficiently.\n",
    "\n",
    "### **3. Addressing Multicollinearity**\n",
    "   - Highly correlated predictors can inflate standard errors, making coefficients unreliable.\n",
    "   - Standardization can help mitigate multicollinearity by adjusting variable distributions.\n",
    "\n",
    "### **4. Improving Comparability of Coefficients**\n",
    "   - In multiple regression, raw coefficients are affected by measurement units (e.g., income vs. age).\n",
    "   - Standardizing makes coefficients unit-independent, enabling direct comparison of their impact.\n",
    "\n",
    "### **5. Facilitating Regularization Techniques**\n",
    "   - Methods like Ridge and Lasso regression rely on scaling to apply penalty terms appropriately.\n",
    "   - Without scaling, regularization can behave unpredictably.\n",
    "\n",
    "### **Common Scaling Methods**\n",
    "   - **Standardization (Z-score scaling)**: Rescales data to a mean of 0 and standard deviation of 1.\n",
    "   - **Min-Max Scaling**: Normalizes values between 0 and 1, useful for preserving data shape.\n",
    "   - **Robust Scaling**: Uses median and interquartile range, effective for handling outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb5d260",
   "metadata": {},
   "source": [
    "**Q23.What is polynomial regression?**\n",
    "   - Polynomial regression is an extension of linear regression that models the relationship between the dependent and independent variables as a polynomial equation rather than a simple linear one. It’s particularly useful when the relationship between variables is non-linear but can be approximated by a polynomial function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac096e6",
   "metadata": {},
   "source": [
    "**Q24.How does polynomial regression differ from linear regression?**\n",
    "   - Polynomial regression differs from linear regression primarily in how it models relationships between variables:\n",
    "\n",
    "### **1. Nature of the Relationship**\n",
    "   - **Linear Regression** assumes a straight-line relationship between the dependent variable (\\( Y \\)) and the independent variable (\\( X \\)).\n",
    "   - **Polynomial Regression** captures non-linear relationships by introducing higher-order terms (\\( X^2, X^3, \\dots \\)), allowing for curvature in the regression line.\n",
    "\n",
    "### **2. Mathematical Equation**\n",
    "   - **Linear Regression:** \\( Y = \\beta_0 + \\beta_1X + \\epsilon \\)\n",
    "   - **Polynomial Regression:** \\( Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\beta_3X^3 + \\dots + \\beta_nX^n + \\epsilon \\)\n",
    "   - The polynomial model fits a curved trend rather than a straight-line approximation.\n",
    "\n",
    "### **3. Flexibility**\n",
    "   - Linear regression can **only** model straight-line trends.\n",
    "   - Polynomial regression allows **more complex patterns**, making it useful for modeling real-world phenomena like growth curves or oscillating behaviors.\n",
    "\n",
    "### **4. Risk of Overfitting**\n",
    "   - Linear models are **simple and interpretable** but may not capture complex patterns.\n",
    "   - Polynomial models **increase the risk of overfitting**, meaning the model might fit noise in the data rather than general trends.\n",
    "\n",
    "### **5. Interpretability of Coefficients**\n",
    "   - In linear regression, coefficients have a straightforward interpretation (i.e., a one-unit increase in \\( X \\) leads to a direct change in \\( Y \\)).\n",
    "   - In polynomial regression, higher-order terms complicate coefficient interpretation, making the relationships harder to intuitively understand.\n",
    "\n",
    "### **6. Use Cases**\n",
    "   - **Linear Regression** works well when the relationship between variables is approximately linear.\n",
    "   - **Polynomial Regression** is useful when data follows a curved pattern, such as modeling stock prices, biological growth, or physical phenomena.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0280a1d5",
   "metadata": {},
   "source": [
    "**Q25.When is polynomial regression used?**\n",
    "  - Polynomial regression is used when the relationship between the independent and dependent variables is non-linear but can still be approximated with a polynomial function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eb1104",
   "metadata": {},
   "source": [
    "**Q26.What is the general equation for polynomial regression?**\n",
    "  - The general equation for **polynomial regression** extends linear regression by including higher-order terms of the independent variable. It follows the form:\n",
    "\n",
    "\\[\n",
    "Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\beta_3X^3 + \\dots + \\beta_nX^n + \\epsilon\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( Y \\) = Dependent variable (target)\n",
    "- \\( X \\) = Independent variable (predictor)\n",
    "- \\( \\beta_0 \\) = Intercept (baseline value when \\( X \\) is zero)\n",
    "- \\( \\beta_1, \\beta_2, \\dots, \\beta_n \\) = Coefficients for polynomial terms\n",
    "- \\( X^n \\) = Higher-degree polynomial terms\n",
    "- \\( \\epsilon \\) = Error term (captures the unexplained variance)\n",
    "\n",
    "### **Key Points**\n",
    "- If **\\( n = 1 \\)**, the model reduces to simple linear regression.\n",
    "- If **\\( n > 1 \\)**, the equation introduces curvature, allowing more flexibility in capturing complex patterns in the data.\n",
    "- Higher-degree polynomials can overfit the data, so selecting an appropriate degree is crucial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd47cbf",
   "metadata": {},
   "source": [
    "**Q27.Can polynomial regression be applied to multiple variables?**\n",
    "   - polynomial regression can be extended to multiple variables, creating a multivariate polynomial regression model. This allows modeling non-linear relationships involving multiple independent variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736278fa",
   "metadata": {},
   "source": [
    "**Q28.What are the limitations of polynomial regression?**\n",
    "   - Polynomial regression can be a powerful tool for modeling non-linear relationships, but it comes with several limitations:\n",
    "\n",
    "### **1. Risk of Overfitting**  \n",
    "   - Higher-degree polynomials can fit the training data very well but may fail to generalize to new data. This leads to poor predictive performance.\n",
    "\n",
    "### **2. Complexity and Interpretability**  \n",
    "   - As the degree of the polynomial increases, the equation becomes more complicated.\n",
    "   - Coefficients of higher-order terms are difficult to interpret, making it harder to understand the impact of predictors.\n",
    "\n",
    "### **3. Sensitivity to Outliers**  \n",
    "   - Polynomial models can be **highly sensitive to outliers**—a few extreme values can distort the curve significantly.\n",
    "   - This can lead to unrealistic predictions.\n",
    "\n",
    "### **4. Computational Cost**  \n",
    "   - With large datasets and high-degree polynomials, the computational cost increases.\n",
    "   - Feature engineering and model tuning become more demanding.\n",
    "\n",
    "### **5. Extrapolation Issues**  \n",
    "   - Polynomial regression may produce **unrealistic predictions** for values outside the observed range.\n",
    "   - The model’s curve can fluctuate wildly at extreme values.\n",
    "\n",
    "### **6. Collinearity in High-Degree Terms**  \n",
    "   - Higher-order polynomial terms tend to be **highly correlated**, leading to numerical instability.\n",
    "   - This can make parameter estimation unreliable.\n",
    "\n",
    "### **7. Selection of Degree**  \n",
    "   - Choosing the right polynomial degree is challenging—too low may underfit the data, while too high may lead to overfitting.\n",
    "   - Cross-validation and domain expertise are necessary to strike the right balance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38888192",
   "metadata": {},
   "source": [
    "**Q29.What methods can be used to evaluate model fit when selecting the degree of a polynomial?**\n",
    "   - Choosing the right polynomial degree is essential to ensure a model captures meaningful patterns **without overfitting or underfitting**. Here are several methods to evaluate model fit:\n",
    "\n",
    "### **1. Cross-Validation**\n",
    "   - **K-Fold Cross-Validation:** Divides the dataset into multiple folds, training on some and testing on others to assess generalization.\n",
    "   - Helps determine whether a higher-degree polynomial improves performance or just memorizes noise.\n",
    "\n",
    "### **2. Residual Analysis**\n",
    "   - **Residual Plots:** Scatter residuals against predicted values—if they show a structured pattern, the polynomial degree might be too low.\n",
    "   - Ideally, residuals should be **randomly scattered** around zero.\n",
    "\n",
    "### **3. Adjusted R²**\n",
    "   - Unlike \\( R^2 \\), which always increases as more terms are added, **adjusted \\( R^2 \\)** penalizes excessive predictors.\n",
    "   - If adjusted \\( R^2 \\) starts dropping, the added complexity is unnecessary.\n",
    "\n",
    "### **4. Mean Squared Error (MSE) & Root Mean Squared Error (RMSE)**\n",
    "   - Lower MSE and RMSE indicate better fit.\n",
    "   - Comparing training and validation errors helps detect **overfitting**—if the training error is low but validation error is high, the polynomial might be **too complex**.\n",
    "\n",
    "### **5. Akaike Information Criterion (AIC) & Bayesian Information Criterion (BIC)**\n",
    "   - **Penalize overly complex models** while rewarding good fit.\n",
    "   - Lower values suggest a better balance between accuracy and simplicity.\n",
    "\n",
    "### **6. Visualization of Polynomial Fits**\n",
    "   - Plot polynomial curves with actual data points to see if the chosen degree **captures trends without excessive fluctuations**.\n",
    "\n",
    "### **7. Variance Inflation Factor (VIF)**\n",
    "   - Evaluates **multicollinearity** among polynomial terms.\n",
    "   - Higher-degree polynomials often introduce **highly correlated terms**, making parameter estimation unstable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710273fe",
   "metadata": {},
   "source": [
    "**Q30. Why is visualization important in polynomial regression?**\n",
    "   - Visualization is crucial in polynomial regression because it helps interpret model behavior, detect issues, and communicate findings effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a554198c",
   "metadata": {},
   "source": [
    "**Q31. How is polynomial regression implemented in Python?**\n",
    "  - Polynomial regression in Python can be implemented using libraries like NumPy, scikit-learn, and matplotlib for visualization.\n",
    "  ### Here’s a step-by-step approach:-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb43fdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Required Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec4b4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Generate Sample Data\n",
    "# Creating synthetic dataset\n",
    "X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(-1, 1)\n",
    "y = np.array([3, 6, 7, 8, 12, 14, 17, 20, 24, 28])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "338fbb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Apply Polynomial Transformation\n",
    "# Transforming X into polynomial features (degree 2)\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "269a5573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">copy_X&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">1e-06</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">positive&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Train the Model\n",
    "# Train polynomial regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28a55599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Make Predictions\n",
    "y_pred = model.predict(X_poly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f299a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#6. Visualize Results\n",
    "plt.scatter(X, y, color='blue', label='Actual Data')\n",
    "plt.plot(X, y_pred, color='red', label='Polynomial Fit')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
